{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bdr import Features\n",
    "from bdr.data.imdb_faces import load_faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../experiments/')\n",
    "import train_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "full = load_faces(load_their_probs=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Features: 19,645 bags with 1 to 796 4083-dimensional points (397,949 total)>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "_split = {}\n",
    "def split(seed, feats=full):\n",
    "    if feats is full and seed in _split:\n",
    "        r = _split[seed]\n",
    "        # have we added any metadata since splitting?\n",
    "        if set(r[0].meta) == set(full.meta):\n",
    "            return _split[seed]\n",
    "    \n",
    "    parser = train_test.make_parser()\n",
    "    args = parser.parse_args(\n",
    "        ['imdb_faces', '--type=fourier', 'fake_out', '--split-seed={}'.format(seed)])\n",
    "    spl = train_test._split_feats(args, feats)\n",
    "    \n",
    "    if feats is full:\n",
    "        _split[seed] = spl\n",
    "    return spl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "seeds = np.arange(20, 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Their model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Method 1: posterior averaging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "_labels = np.arange(101)\n",
    "\n",
    "def cdf_vals(discrete_preds, y):\n",
    "    pred_cdfs = np.cumsum(discrete_preds, axis=1)\n",
    "    \n",
    "    lo = y.astype(int)\n",
    "    portion = y % 1\n",
    "    lo_cdf = pred_cdfs[range(len(y)), lo]\n",
    "    hi_cdf = pred_cdfs[range(len(y)), lo + 1]\n",
    "    return lo_cdf + (hi_cdf - lo_cdf) * portion\n",
    "\n",
    "def _do_posterior(posteriors, y, d, name):\n",
    "    s = partial('{}_{}'.format, name)\n",
    "    d[s('y')] = y\n",
    "    d[s('preds')] = preds = posteriors.dot(_labels)\n",
    "    d[s('pred_vars')] = posteriors.dot(_labels ** 2) - preds ** 2\n",
    "    d[s('pred_nlls')] = pred_nlls = -np.log(posteriors[range(len(y)), y.round().astype(int)]).mean()\n",
    "    d[s('pred_cdfs')] = pred_cdfs = cdf_vals(posteriors, y)\n",
    "    d[s('mse')] = mean_squared_error(y, preds)\n",
    "    d[s('r2')] = r2_score(y, preds)\n",
    "    d[s('nll')] = pred_nlls.mean()\n",
    "    d[s('coverage')] = ((0.025 < pred_cdfs) & (pred_cdfs < 0.975)).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p theirs_avg\n",
    "for seed in seeds:\n",
    "    train, estop, val, test = split(seed)\n",
    "    d = {}\n",
    "    for name, ds in [('val', val), ('test', test)]:\n",
    "        posteriors = np.vstack([np.mean(x, axis=0) for x in ds.probs])\n",
    "        _do_posterior(posteriors, ds.y, d, name)    \n",
    "    np.savez('theirs_avg/seed_{}.npz'.format(seed), **d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Method 2: Bayes Rule\n",
    "Let $y$ be the bag label, $x_i$ the $i$th observation, then we have:\n",
    "\\begin{align}\n",
    "     p(y \\mid x_{1:n})\n",
    "  &= \\frac{p(x_{1:n} \\mid y) p(y)}{p(x_{1:n})}\n",
    "\\\\&= \\frac{p(y)}{p(x_{1:n})} \\prod_i p(x_i \\mid y)\n",
    "\\\\&= \\frac{p(y)}{p(x_{1:n})} \\prod_i \\frac{p(y \\mid x_i) p(x_i)}{p(y)}\n",
    "\\\\&= p(y)^{1-n} \\frac{\\prod_i p(x_i)}{p(x_{1:n})} \\prod_i p(y \\mid x_i)\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take $p(y)$ as the empirical distribution on training data; second term is just a normalizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nfs/nhome/live/dougals/anaconda/envs/bdr/lib/python3.6/site-packages/ipykernel/__main__.py:17: RuntimeWarning: divide by zero encountered in log\n"
     ]
    }
   ],
   "source": [
    "!mkdir -p theirs_bayes\n",
    "\n",
    "def _ycount(ds):\n",
    "    r = np.bincount(ds.y.round().astype(int), minlength=101)\n",
    "    assert r.shape == (101,)\n",
    "    return r\n",
    "\n",
    "from scipy.special import logsumexp\n",
    "def norm(log_preds):\n",
    "    return np.exp(log_preds - logsumexp(log_preds, axis=1, keepdims=True))\n",
    "\n",
    "for seed in seeds:\n",
    "    train, estop, val, test = split(seed)\n",
    "    d = {}\n",
    "    for name, ds in [('val', val), ('test', test)]:\n",
    "        ycount = _ycount(train) + _ycount(estop)\n",
    "        if name == 'test':\n",
    "            ycount += _ycount(val)\n",
    "        ycount += 1  # slight prior to avoid zeros\n",
    "        log_py = np.log(ycount) - np.log(ycount.sum())\n",
    "        \n",
    "        log_pred_probs = np.vstack([\n",
    "            np.log(np.vstack(x).astype(np.float64)).sum(axis=0)\n",
    "            for x in ds.probs\n",
    "        ])\n",
    "        \n",
    "        posteriors = norm(log_pred_probs - (ds.n_pts - 1)[:, np.newaxis] * log_py[np.newaxis, :])\n",
    "        _do_posterior(posteriors, ds.y, d, name)\n",
    "    np.savez('theirs_bayes/seed_{}.npz'.format(seed), **d)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:bdr]",
   "language": "python",
   "name": "conda-env-bdr-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
